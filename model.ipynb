{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing data and data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import necesary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2994527  0.00547303 0.2994527  ... 0.06176701 0.43784206 0.06176701]\n",
      " [0.48084441 0.33854574 0.48084441 ... 0.13760751 0.48006255 0.13760751]\n",
      " [0.83580923 0.10476935 0.83580923 ... 0.12666145 0.54573886 0.10007819]\n",
      " ...\n",
      " [0.97107115 0.15011728 0.97107115 ... 0.06567631 0.56919468 0.07114934]\n",
      " [0.60125098 0.00703675 0.60125098 ... 0.06098514 0.50195465 0.06176701]\n",
      " [0.30101642 0.34089132 0.30101642 ... 0.14073495 0.45895231 0.13682565]]\n",
      "[1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Prepare training data\n",
    "training_data = []\n",
    "\n",
    "# Hold training\n",
    "with open('hold_training.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for coordSet in data['coords']:\n",
    "        training_data.append([coordSet['mousePos'],0]) # 0 is hold\n",
    "        \n",
    "# Spill training\n",
    "with open('spill_training.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for coordSet in data['coords']:\n",
    "        # Convert and append mousePosArr\n",
    "        training_data.append([coordSet['mousePos'],1]) # 1 is spill\n",
    "\n",
    "# Shuffling\n",
    "random.shuffle(training_data)\n",
    "\n",
    "# Extract\n",
    "train_coords = []\n",
    "train_labels = []\n",
    "minVal = float('inf')\n",
    "maxVal = 0\n",
    "for sample in training_data:\n",
    "    train_coords.append(sample[0])\n",
    "    train_labels.append(sample[1])\n",
    "    minVal = min(minVal, min(sample[0]))\n",
    "    maxVal = max(maxVal, max(sample[0]))\n",
    "# Normalize\n",
    "difVal = maxVal - minVal\n",
    "for i in range(len(train_coords)):\n",
    "    for j in range(len(train_coords[i])):\n",
    "        train_coords[i][j] = (train_coords[i][j] - minVal) / float(difVal)\n",
    "    # Convert to np array\n",
    "    train_coords[i] = np.asarray(train_coords[i])\n",
    "\n",
    "# Convert\n",
    "train_coords = np.asarray(train_coords)\n",
    "train_labels = np.asarray(train_labels)\n",
    "print(train_coords)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25929127 0.07260156 0.25929127 ... 0.08556612 0.4684529  0.08643042]\n",
      " [0.80207433 0.17199654 0.80207433 ... 0.1227312  0.59982714 0.12100259]\n",
      " [0.35609334 0.01037165 0.35609334 ... 0.07778738 0.50648228 0.07778738]\n",
      " ...\n",
      " [0.83837511 0.1426102  0.83837511 ... 0.1642178  0.51512532 0.1642178 ]\n",
      " [0.94122731 0.15816768 0.94122731 ... 0.17286085 0.5911841  0.17286085]\n",
      " [0.21866897 0.07778738 0.21866897 ... 0.10025929 0.43301642 0.10025929]]\n",
      "[1 0 0 1 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Prepare testing data\n",
    "testing_data = []\n",
    "\n",
    "# Hold testing\n",
    "with open('hold_testing.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for coordSet in data['coords']:\n",
    "        testing_data.append([coordSet['mousePos'],0]) # 0 is hold\n",
    "        \n",
    "# Spill training\n",
    "with open('spill_testing.json') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    for coordSet in data['coords']:\n",
    "        # Convert and append mousePosArr\n",
    "        testing_data.append([coordSet['mousePos'],1]) # 1 is spill\n",
    "\n",
    "# Shuffling\n",
    "random.shuffle(testing_data)\n",
    "\n",
    "# Extract\n",
    "test_coords = []\n",
    "test_labels = []\n",
    "minVal = float('inf')\n",
    "maxVal = 0\n",
    "for sample in testing_data:\n",
    "    test_coords.append(sample[0])\n",
    "    test_labels.append(sample[1])\n",
    "    minVal = min(minVal, min(sample[0]))\n",
    "    maxVal = max(maxVal, max(sample[0]))\n",
    "# Normalize\n",
    "difVal = maxVal - minVal\n",
    "for i in range(len(test_coords)):\n",
    "    for j in range(len(test_coords[i])):\n",
    "        test_coords[i][j] = (test_coords[i][j] - minVal) / float(difVal)\n",
    "    # Convert to np array\n",
    "    test_coords[i] = np.asarray(test_coords[i])\n",
    "\n",
    "# Convert\n",
    "test_coords = np.asarray(test_coords)\n",
    "test_labels = np.asarray(test_labels)\n",
    "print(test_coords)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "#     keras.layers.Flatten(input_shape=(1,300)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 09:42:40.266690 4486510016 deprecation.py:323] From /Users/tgoh/Documents/sippy-cup/env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "20/20 [==============================] - 0s 3ms/sample - loss: 0.7095 - acc: 0.5500\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.6664 - acc: 0.7500\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.6402 - acc: 0.5000\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 70us/sample - loss: 0.5998 - acc: 0.8500\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 62us/sample - loss: 0.5802 - acc: 0.8500\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 84us/sample - loss: 0.5570 - acc: 0.9000\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.5383 - acc: 0.8500\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.5251 - acc: 0.8000\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.5081 - acc: 0.8500\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 93us/sample - loss: 0.4944 - acc: 0.9000\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.4831 - acc: 0.9000\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.4693 - acc: 0.9000\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 57us/sample - loss: 0.4573 - acc: 0.8500\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 0.4481 - acc: 0.7500\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.4379 - acc: 0.8000\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.4278 - acc: 0.8500\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.4197 - acc: 0.9000\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.4116 - acc: 0.9000\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 91us/sample - loss: 0.4034 - acc: 0.8500\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 81us/sample - loss: 0.3967 - acc: 0.8500\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 86us/sample - loss: 0.3901 - acc: 0.8500\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 97us/sample - loss: 0.3831 - acc: 0.8500\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 99us/sample - loss: 0.3770 - acc: 0.9000\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 100us/sample - loss: 0.3713 - acc: 0.9000\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 80us/sample - loss: 0.3651 - acc: 0.8500\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 77us/sample - loss: 0.3594 - acc: 0.8500\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.3540 - acc: 0.8500\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 95us/sample - loss: 0.3483 - acc: 0.8500\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 102us/sample - loss: 0.3428 - acc: 0.8500\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 78us/sample - loss: 0.3376 - acc: 0.8500\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 84us/sample - loss: 0.3321 - acc: 0.8500\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.3268 - acc: 0.8500\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 76us/sample - loss: 0.3218 - acc: 0.8500\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 75us/sample - loss: 0.3167 - acc: 0.8500\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 82us/sample - loss: 0.3114 - acc: 0.8500\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 73us/sample - loss: 0.3066 - acc: 0.8500\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 69us/sample - loss: 0.3015 - acc: 0.8500\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 63us/sample - loss: 0.2965 - acc: 0.8500\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 55us/sample - loss: 0.2915 - acc: 0.8500\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.2866 - acc: 0.8500\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 66us/sample - loss: 0.2818 - acc: 0.9000\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 61us/sample - loss: 0.2768 - acc: 0.9000\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 67us/sample - loss: 0.2721 - acc: 0.9000\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 83us/sample - loss: 0.2673 - acc: 0.9500\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 68us/sample - loss: 0.2625 - acc: 0.9500\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 60us/sample - loss: 0.2578 - acc: 0.9000\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 71us/sample - loss: 0.2530 - acc: 0.9000\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 81us/sample - loss: 0.2483 - acc: 0.9500\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 88us/sample - loss: 0.2438 - acc: 0.9500\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 59us/sample - loss: 0.2391 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x102d143c8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_coords, train_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "20/20 [==============================] - 0s 926us/sample - loss: 0.5678 - acc: 0.6500\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_coords, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5495354  0.4504646 ]\n",
      " [0.79685175 0.20314825]\n",
      " [0.7893279  0.2106721 ]\n",
      " [0.56672955 0.43327048]\n",
      " [0.9652034  0.03479658]\n",
      " [0.62908685 0.37091315]\n",
      " [0.6171704  0.38282967]\n",
      " [0.01181204 0.98818797]\n",
      " [0.9289684  0.07103157]\n",
      " [0.36187607 0.6381239 ]\n",
      " [0.89591795 0.10408203]\n",
      " [0.95235723 0.04764277]\n",
      " [0.86622196 0.13377799]\n",
      " [0.94987434 0.0501257 ]\n",
      " [0.31448403 0.68551594]\n",
      " [0.14031948 0.85968053]\n",
      " [0.63492066 0.36507934]\n",
      " [0.6817806  0.31821942]\n",
      " [0.40717795 0.5928221 ]\n",
      " [0.73495054 0.26504946]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_coords)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python model\n",
    "model.save('Model/model.h5')\n",
    "# JS model\n",
    "tfjs.converters.save_keras_model(model, './Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
